{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "from PIL import Image\n",
    "import io\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'data.csv' with the path to your CSV file\n",
    "df_test = pd.read_csv('26a3f9eddc82d3907db7749c34f68938_test.csv')\n",
    "df_train = pd.read_csv('26a3f9eddc82d3907db7749c34f68938_train.csv')\n",
    "df_val = pd.read_csv('26a3f9eddc82d3907db7749c34f68938_val.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMPERATURE FOR TUNING OF PROBABILITY\n",
    "T = 1.066\n",
    "\n",
    "def sigmoid(x, T=T):\n",
    "    return 1 / (1 + np.exp(-x/T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5927232152574935"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def process_row(row, save_dir='image_copy'):\n",
    "    # Read the Parquet file\n",
    "    parquet_path = row['file_path']\n",
    "    if not os.path.exists(parquet_path):\n",
    "        print(f\"File not found: {parquet_path}\")\n",
    "        return None\n",
    "    \n",
    "    df_parquet = pd.read_parquet(parquet_path)\n",
    "    \n",
    "    # Convert DataFrame to numpy array\n",
    "    data_array = df_parquet.values.T.astype(np.uint8)\n",
    "\n",
    "    assert data_array.max() <= 255\n",
    "    assert data_array.min() >= 0\n",
    "\n",
    "    # Create an image from the array\n",
    "    image = Image.fromarray(data_array, mode='L')\n",
    "\n",
    "    # Create file path to save the image\n",
    "    img_filename = f\"{row['antenna']}_{row['datetime']}.png\"\n",
    "    img_save_path = os.path.join(save_dir, img_filename)\n",
    "\n",
    "    # Save the image to disk\n",
    "    image.save(img_save_path, format='PNG')\n",
    "    \n",
    "    # Prepare the example dictionary\n",
    "    example = {\n",
    "        'image': img_save_path,\n",
    "        'manual_label': int(row['label']),\n",
    "        'logits': float(row['pred']),\n",
    "        'prob': sigmoid(row['pred']),\n",
    "        'model_label': int(row['pred'] > 0),\n",
    "        'start_datetime': pd.to_datetime(row['datetime']), \n",
    "        'antenna': row['antenna']\n",
    "    }\n",
    "    \n",
    "    return example, df_parquet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_test = []\n",
    "for index, row in tqdm(df_test.iterrows(), total=len(df_test)):\n",
    "    example, spectro = process_row(row)\n",
    "    if example is not None:\n",
    "        examples_test.append(example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/24439 [00:01<1:52:50,  3.61it/s]\n"
     ]
    }
   ],
   "source": [
    "examples_train = []\n",
    "for index, row in tqdm(df_train.iterrows(), total=len(df_train)):\n",
    "    example, spectro = process_row(row)\n",
    "    if example is not None:\n",
    "        examples_train.append(example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/6110 [00:01<19:15,  5.28it/s]\n"
     ]
    }
   ],
   "source": [
    "examples_val = []\n",
    "for index, row in tqdm(df_val.iterrows(), total=len(df_val)):\n",
    "    example, spectro = process_row(row)\n",
    "    if example is not None:\n",
    "        examples_val.append(example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vincenzo/miniconda3/envs/flaresense-v2/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'examples_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m dd \u001b[38;5;241m=\u001b[39m DatasetDict()\n\u001b[1;32m      4\u001b[0m dd[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mfrom_pandas(pd\u001b[38;5;241m.\u001b[39mDataFrame(examples_test))\u001b[38;5;241m.\u001b[39mcast_column(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m, datasets\u001b[38;5;241m.\u001b[39mImage(decode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[0;32m----> 5\u001b[0m dd[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mfrom_pandas(pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mexamples_val\u001b[49m))\u001b[38;5;241m.\u001b[39mcast_column(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m, datasets\u001b[38;5;241m.\u001b[39mImage(decode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[1;32m      6\u001b[0m dd[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mfrom_pandas(pd\u001b[38;5;241m.\u001b[39mDataFrame(examples_train))\u001b[38;5;241m.\u001b[39mcast_column(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m, datasets\u001b[38;5;241m.\u001b[39mImage(decode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'examples_val' is not defined"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "import datasets\n",
    "dd = DatasetDict()\n",
    "dd['test'] = Dataset.from_pandas(pd.DataFrame(examples_test)).cast_column('image', datasets.Image(decode=False))\n",
    "dd['val'] = Dataset.from_pandas(pd.DataFrame(examples_val)).cast_column('image', datasets.Image(decode=False))\n",
    "dd['train'] = Dataset.from_pandas(pd.DataFrame(examples_train)).cast_column('image', datasets.Image(decode=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 7/7 [00:00<00:00, 1193.99 examples/s], ?it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 301.57ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  3.26it/s]\n",
      "Map: 100%|██████████| 7/7 [00:00<00:00, 1444.18 examples/s], ?it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 349.96ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  3.93it/s]\n",
      "Map: 100%|██████████| 7/7 [00:00<00:00, 1430.88 examples/s], ?it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 357.02ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/i4ds/ecallisto_test/commit/dfccc448dd7f47936f0a37912bb4e8a44d033d2f', commit_message='Upload dataset', commit_description='', oid='dfccc448dd7f47936f0a37912bb4e8a44d033d2f', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd.push_to_hub('i4ds/ecallisto_radio_sunburst', token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flaresense-v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
